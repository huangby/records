https://colab.research.google.com/notebooks/mlcc/first_steps_with_tensor_flow.ipynb?hl=zh-cn#scrollTo=rVFf5asKE2Zt


import math
from IPython import display
from matplotlib import cm
from matplotlib import gridspec
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
from sklearn import metrics
import tensorflow as tf
from tensorflow.python.data import Dataset
tf.logging.set_verbosity(tf.logging.ERROR)
pd.options.display.max_rows = 10
pd.options.display.float_format = '{:.1f}'.format


def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):
    #该函数定义输入，features是特征值，targets是标记值，batch_size每一批数据的大小，shuffle：是否随机处理，num_epochs：周期数
    # 从pd数据转换为numpy数据
    features = {key:np.array(value) for key,value in dict(features).items()}                                           
 
    # 构建 Dataset 对象
    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit
    # 设置数据拆分成大小，并设置重复次数，None会无限制重复
    ds = ds.batch(batch_size).repeat(num_epochs)
    
    # 是否设置随机处理，如果设置随机，则会在buffer_size大小的范围内进行随机处理
    if shuffle:
      ds = ds.shuffle(buffer_size=10000)
    # 返回数据，每一次调用都会返回下一个批次的数据及对应的标签
    features, labels = ds.make_one_shot_iterator().get_next()
    return features, labels
  
def train_model(learning_rate, steps, batch_size, input_feature="total_rooms"):
  #循环次数
  periods = 10
  #每次循环需要进行的步数
  steps_per_period = steps / periods
  
  #输入的特征属性
  my_feature = input_feature
  #从数据集中获取特征值
  my_feature_data = california_housing_dataframe[[my_feature]]
  #标签
  my_label = "median_house_value"
  #标签值
  targets = california_housing_dataframe[my_label]

  # 设置特征列，在 TensorFlow 中，使用一种称为“特征列”的结构来表示特征的数据类型。特征列仅存储对特征数据的描述；不包含特征数据本身。
  feature_columns = [tf.feature_column.numeric_column(my_feature)]
  
  # 创建训练集
  training_input_fn = lambda:my_input_fn(my_feature_data, targets, batch_size=batch_size)
  # 创建测试集
  prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)
  
  # 创建SGD（随机梯度下降）
  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
  
  # 设置梯度剪裁(即上限)
  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)
  
  # 创建线性回归
  linear_regressor = tf.estimator.LinearRegressor(
      feature_columns=feature_columns,
      optimizer=my_optimizer
  )

  # 设置图表
  plt.figure(figsize=(15, 6))
  plt.subplot(1, 2, 1)
  plt.title("Learned Line by Period")
  plt.ylabel(my_label)
  plt.xlabel(my_feature)
  sample = california_housing_dataframe.sample(n=300)
  plt.scatter(sample[my_feature], sample[my_label])
  colors = [cm.coolwarm(x) for x in np.linspace(-1, 1, periods)]
  
  # 开始训练
  # loss metrics.
  print "Training model..."
  print "RMSE (on training data):"
  root_mean_squared_errors = []
  for period in range (0, periods):
    # Train the model, starting from the prior state.
    
    linear_regressor.train(
        input_fn=training_input_fn,
        steps=steps_per_period
    )
    # Take a break and compute predictions.
    predictions = linear_regressor.predict(input_fn=prediction_input_fn)
    predictions = np.array([item['predictions'][0] for item in predictions])
    
    # Compute loss.
    root_mean_squared_error = math.sqrt(
        metrics.mean_squared_error(predictions, targets))
    # Occasionally print the current loss.
    print "  period %02d : %0.2f" % (period, root_mean_squared_error)
    # Add the loss metrics from this period to our list.
    root_mean_squared_errors.append(root_mean_squared_error)
    # Finally, track the weights and biases over time.
    # Apply some math to ensure that the data and line are plotted neatly.
    y_extents = np.array([0, sample[my_label].max()])
    
    weight = linear_regressor.get_variable_value('linear/linear_model/%s/weights' % input_feature)[0]
    bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')

    x_extents = (y_extents - bias) / weight
    x_extents = np.maximum(np.minimum(x_extents,
                                      sample[my_feature].max()),
                           sample[my_feature].min())
    y_extents = weight * x_extents + bias
    plt.plot(x_extents, y_extents, color=colors[period]) 
  print "Model training finished."
  # Output a graph of loss metrics over periods.
  plt.subplot(1, 2, 2)
  plt.ylabel('RMSE')
  plt.xlabel('Periods')
  plt.title("Root Mean Squared Error vs. Periods")
  plt.tight_layout()
  plt.plot(root_mean_squared_errors)

  # Output a table with calibration data.
  calibration_data = pd.DataFrame()
  calibration_data["predictions"] = pd.Series(predictions)
  calibration_data["targets"] = pd.Series(targets)
  display.display(calibration_data.describe())
  print "Final RMSE (on training data): %0.2f" % root_mean_squared_error
train_model(
    learning_rate=0.00002,
    steps=500,
    batch_size=5
)
